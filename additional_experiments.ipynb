{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 13:00:27.306361: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.constraints import maxnorm, nonneg, unit_norm\n",
    "import os\n",
    "import gc\n",
    "from argparse import ArgumentParser\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Conv1D, Activation, Lambda, Permute, Conv2D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from itertools import permutations\n",
    "\n",
    "from math import comb\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import Ridge\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape info: [(159, 10), (159,), (575, 10), (575,)]\n",
      "k: 5\n",
      "True Indices: [0, 2, 3, 6, 7]\n",
      "Model: \"cyclic_group_invariance_discover_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  990       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             multiple                  990       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             multiple                  8190      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             multiple                  48        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             multiple                  1088      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             multiple                  8320      \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             multiple                  8192      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             multiple                  4096      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  2048      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             multiple                  1024      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             multiple                  33        \n",
      "=================================================================\n",
      "Total params: 35,129\n",
      "Trainable params: 24,849\n",
      "Non-trainable params: 10,280\n",
      "_________________________________________________________________\n",
      "None\n",
      "At shape: (3069, 14)\n"
     ]
    }
   ],
   "source": [
    "Z2 = [[0, 1], [1, 0]]\n",
    "Z4 = [[0, 1, 2, 3], [1, 2, 3, 0], [2, 3, 0, 1], [3, 0, 1, 2]]\n",
    "Z5 = [[0, 1, 2, 3, 4], [1, 2, 3, 4, 0], [2, 3, 4, 0, 1], [3, 4, 0, 1, 2], [4, 0, 1, 2, 3]]\n",
    "Z8 = [[0, 1, 2, 3, 4, 5, 6, 7], [7, 0, 1, 2, 3, 4, 5, 6], [6, 7, 0, 1, 2, 3, 4, 5], [5, 6, 7, 0, 1, 2, 3, 4],\n",
    "[4, 5, 6, 7, 0, 1, 2, 3], [3, 4, 5, 6, 7, 0, 1, 2], [2, 3, 4, 5, 6, 7, 0, 1], [1, 2, 3, 4, 5, 6, 7, 0]]\n",
    "\n",
    "perm = [[0, 1, 2, 3], [1, 2, 3, 0], [2, 3, 0, 1], [3, 0, 1, 2],\n",
    "    [3, 2, 1, 0], [2, 1, 0, 3], [1, 0, 3, 2], [0, 3, 2, 1]]\n",
    "\n",
    "Z5_Z10 = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [4, 0, 1, 2, 3, 5, 6, 7, 8, 9],\n",
    "    [3, 4, 0, 1, 2, 5, 6, 7, 8, 9], [2, 3, 4, 0, 1, 5, 6, 7, 8, 9],\n",
    "    [1, 2, 3, 4, 0, 5, 6, 7, 8, 9]]\n",
    "\n",
    "Z10 = [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [9, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "[8, 9, 0, 1, 2, 3, 4, 5, 6, 7],  [7, 8, 9, 0, 1, 2, 3, 4, 5, 6],\n",
    "[6, 7, 8, 9, 0, 1, 2, 3, 4, 5],  [5, 6, 7, 8, 9, 0, 1, 2, 3, 4],\n",
    "[4, 5, 6, 7, 8, 9, 0, 1, 2, 3],  [3, 4, 5, 6, 7, 8, 9, 0, 1, 2],\n",
    "[2, 3, 4, 5, 6, 7, 8, 9, 0, 1],  [1, 2, 3, 4, 5, 6, 7, 8, 9, 0,]]\n",
    "\n",
    "def generate_per_matrix(n):\n",
    "#P = np.zeros((n,n)).astype(np.int64)\n",
    "atom = np.arange(n)\n",
    "P = np.array([np.roll(atom, shift=i) for i in np.arange(n)])\n",
    "return P\n",
    "\n",
    "def poly_Zk_Zn(x, indices):\n",
    "def inv1(a, b):\n",
    "    return a * b ** 2\n",
    "\n",
    "unstacked_variables  = tf.unstack(x, axis=1)\n",
    "unstacked_variables = tf.gather(unstacked_variables, indices)\n",
    "\n",
    "q1 = 0\n",
    "for i in np.arange(len(indices)-1):\n",
    "    q1 += inv1(unstacked_variables[i], unstacked_variables[i+1])\n",
    "q1 += inv1(unstacked_variables[len(indices)-1], unstacked_variables[0])        \n",
    "return q1\n",
    "\n",
    "def apply_layers(x, layers):\n",
    "for l in layers:\n",
    "    x = l(x)\n",
    "return x\n",
    "\n",
    "def sigmaPi(fin, m, n, p):\n",
    "fin = tf.transpose(fin, (0, 2, 1, 3))\n",
    "fin = fin[:, :, tf.newaxis]\n",
    "fin = tf.tile(fin, (1, 1, m, 1, 1))\n",
    "y = fin @ p\n",
    "y = tf.linalg.diag_part(y)\n",
    "y = tf.reduce_prod(y, axis=3)\n",
    "y = tf.reduce_sum(y, axis=2)\n",
    "return y\n",
    "\n",
    "def prepare_permutation_matices(perm, n, m):\n",
    "p1 = np.eye(n, dtype=np.float32)\n",
    "p = np.tile(p1[np.newaxis], (m, 1, 1))\n",
    "for i, x in enumerate(perm):\n",
    "    p[i, x, :] = p1[np.arange(n)]\n",
    "return p \n",
    "        \n",
    "def get_matrix(d):\n",
    "I = np.eye(d)\n",
    "M1 = np.vstack([I]*((d-1)))\n",
    "P = np.roll(I,1,axis=-1)\n",
    "M2 = P@I\n",
    "P_ = P\n",
    "for i in range(1,d-1):\n",
    "    P1 = P_@P\n",
    "    M2 = np.vstack((M2,P1@I))\n",
    "    P_ = P1\n",
    "return M1,M2\n",
    "\n",
    "class GroupInvariance(tf.keras.Model):\n",
    "def __init__(self, perm, num_features):\n",
    "    super(GroupInvariance, self).__init__()\n",
    "    activation=tf.keras.activations.tanh\n",
    "\n",
    "    self.num_features = num_features\n",
    "    self.n = len(perm[0])\n",
    "    self.m = len(perm)\n",
    "    self.p = prepare_permutation_matices(perm, self.n, self.m)\n",
    "\n",
    "    self.features = [\n",
    "        tf.keras.layers.Dense(16, activation),\n",
    "        tf.keras.layers.Dense(64, activation),\n",
    "        tf.keras.layers.Dense(self.n * self.num_features, tf.keras.activations.sigmoid),\n",
    "        #tf.keras.layers.Dense(self.n * self.num_features, None),\n",
    "    ]\n",
    "\n",
    "    self.fc = [\n",
    "        #tf.keras.layers.Dense(32, tf.keras.activations.tanh),\n",
    "        tf.keras.layers.Dense(32, tf.keras.activations.relu, use_bias=False),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    "\n",
    "def call(self, inputs):\n",
    "    x = inputs[:, :, tf.newaxis]\n",
    "    x = apply_layers(x, self.features)\n",
    "    x = tf.reshape(x, (-1, self.n, self.num_features, self.n))\n",
    "    x = sigmaPi(x, self.m, self.n, self.p)\n",
    "    x = apply_layers(x, self.fc)\n",
    "    return x\n",
    "\n",
    "np.random.seed(1024)\n",
    "ts = 64\n",
    "vs = 480\n",
    "d = 10\n",
    "divisors = [1, 2, 5, 10]\n",
    "k = 5\n",
    "\n",
    "def get_data(x, train_indices):\n",
    "P = np.zeros((d, d))\n",
    "p_indices = np.roll(train_indices, 1)\n",
    "j = 0\n",
    "for i in range(d):\n",
    "    if i in train_indices:\n",
    "        P[i][p_indices[j]] = 1\n",
    "        j += 1\n",
    "    else:\n",
    "        P[i][i] = 1\n",
    "\n",
    "c_train_ds = []\n",
    "P1 = P\n",
    "for i in range(len(train_indices)-1):\n",
    "    c_train_ds.append(np.dot(P1, x))\n",
    "    P1 = P@P1\n",
    "\n",
    "p_indices = np.array(list(permutations(train_indices)))\n",
    "random_indices = list(np.random.choice(len(p_indices), size=2*k, replace=False))\n",
    "new_indices = p_indices[random_indices]\n",
    "\n",
    "p_train_ds = []\n",
    "for i in range(2*k):\n",
    "    y = x.copy()\n",
    "    y[train_indices] = y[new_indices[i]]\n",
    "    p_train_ds.append(y)\n",
    "\n",
    "return np.array(c_train_ds), np.array(p_train_ds)\n",
    "\n",
    "def get_data_v1(x, train_indices):\n",
    "P = np.zeros((d, d))\n",
    "p_indices = np.roll(train_indices, 1)\n",
    "j = 0\n",
    "for i in range(d):\n",
    "    if i in train_indices:\n",
    "        P[i][p_indices[j]] = 1\n",
    "        j += 1\n",
    "    else:\n",
    "        P[i][i] = 1\n",
    "\n",
    "P = P.T\n",
    "c_train_ds = [np.dot(x, P)]\n",
    "for i in range(len(train_indices)-2):\n",
    "    c_train_ds.append(np.dot(c_train_ds[-1], P))\n",
    "\n",
    "P1 = np.eye(d)\n",
    "id0 = train_indices[0]\n",
    "id1 = train_indices[1]\n",
    "P1[[id0,id1]] = P1[[id1,id0]]\n",
    "d_train_ds = [np.dot(x, P1)]\n",
    "for i in range(len(train_indices)-1):\n",
    "    d_train_ds.append(np.dot(d_train_ds[-1], P))      \n",
    "\n",
    "p_indices = np.array(list(permutations(train_indices)))\n",
    "random_indices = list(np.random.choice(len(p_indices), size=2*k, replace=False))\n",
    "new_indices = p_indices[random_indices]\n",
    "\n",
    "p_train_ds = []\n",
    "for i in range(2*k):\n",
    "    y = x.copy()\n",
    "    y[:,train_indices] = y[:,new_indices[i]]\n",
    "    p_train_ds.append(y)\n",
    "\n",
    "return np.concatenate(c_train_ds, axis=0), np.concatenate(d_train_ds, axis=0), np.concatenate(p_train_ds, axis=0)   \n",
    "\n",
    "def create_data(d, k, batch_size, true_indices):\n",
    "train_ds = np.random.rand(ts*batch_size, d)\n",
    "val_ds = np.random.rand(vs*batch_size, d)\n",
    "indices = np.array(true_indices).astype(np.int64)\n",
    "\n",
    "# Additional data\n",
    "c_train_ds, d_train_ds, p_train_ds = get_data_v1(train_ds[0:5], true_indices)\n",
    "train_ds = np.vstack((train_ds, c_train_ds, d_train_ds, p_train_ds))\n",
    "train_y = poly_Zk_Zn(train_ds, indices).numpy()\n",
    "\n",
    "c_val_ds, d_val_ds, p_val_ds = get_data_v1(val_ds[0:5], true_indices)\n",
    "val_ds = np.vstack((val_ds, c_val_ds, d_val_ds, p_val_ds))\n",
    "val_y = poly_Zk_Zn(val_ds, indices).numpy()\n",
    "\n",
    "print(\"Shape info:\", [train_ds.shape, train_y.shape, val_ds.shape, val_y.shape])\n",
    "return train_ds, train_y, val_ds, val_y\n",
    "\n",
    "n_eps = 0\n",
    "true_indices = [0, 2, 3, 6, 7]\n",
    "train_ds, train_y, val_ds, val_y = create_data(d, k, 1, true_indices)\n",
    "train_y = train_y + n_eps*(np.std(train_y))\n",
    "val_y = val_y + n_eps*(np.std(val_y))\n",
    "print('k:',k)\n",
    "print('True Indices:',true_indices)\n",
    "\n",
    "def my_regularizer(x):\n",
    "#x = tf.abs(x) + 1e-8\n",
    "x = x/(tf.reduce_sum(x, axis=0))\n",
    "entropy = tf.reduce_mean(tf.reduce_sum(-x*tf.math.log(x), axis=0))\n",
    "return 1e-5 * entropy\n",
    "\n",
    "lambda_val = 1e-02\n",
    "l2_reg = tf.keras.regularizers.l2(1e-5)\n",
    "class CyclicGroupInvarianceDiscover(tf.keras.Model):\n",
    "def __init__(self, d):\n",
    "    super(CyclicGroupInvarianceDiscover, self).__init__()\n",
    "    activation = tf.keras.activations.tanh\n",
    "    self.d = d\n",
    "\n",
    "    self.linear1 = Dense(d,activation=None)\n",
    "    self.inputs1 = Dense(d * (d-1),use_bias=True,activation=None)\n",
    "    self.inputs2 = Dense(d * (d-1),use_bias=True,activation=None)\n",
    "    self.linear2 = Dense(d * (d-1),activation=None)\n",
    "\n",
    "    self.features = [\n",
    "        tf.keras.layers.Dense(16, activation, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(64, activation, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(128, activation, kernel_regularizer=l2_reg),\n",
    "    ]\n",
    "\n",
    "    self.Add = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x, axis=1), output_shape=(lambda shape: (shape[0], shape[2])))\n",
    "    self.fc = [\n",
    "        tf.keras.layers.Dense(64, tf.keras.activations.relu, use_bias=False, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(64, tf.keras.activations.relu, use_bias=False, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(32, tf.keras.activations.relu, use_bias=False, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(32, tf.keras.activations.relu, use_bias=False, kernel_regularizer=l2_reg),\n",
    "        tf.keras.layers.Dense(1, kernel_regularizer=l2_reg),\n",
    "    ]\n",
    "    \n",
    "def call(self, inputs):\n",
    "    inputs = self.linear1(inputs)                   # (B, d)\n",
    "    in1 = self.inputs1(inputs)                      # (B, d*(d-1))\n",
    "    in1 = self.linear2(in1)[:, :, tf.newaxis]       # (B, d*(d-1), 1)\n",
    "    in2 = self.inputs2(inputs)                      # (B, d*(d-1))\n",
    "    in2 = self.linear2(in2)[:, :, tf.newaxis]       # (B, d*(d-1), 1)\n",
    "\n",
    "    x = tf.concat((in1,in2), axis=-1)               # (B, d*(d-1), 2)             \n",
    "    x = apply_layers(x, self.features)\n",
    "    x = self.Add(x)\n",
    "    x = apply_layers(x, self.fc)\n",
    "    return x               \n",
    "\n",
    "def new_matrix(k,d,indices,subgroup_indices):\n",
    "M3 = np.zeros((d,d))\n",
    "for row,index in zip(np.arange(k),indices):\n",
    "    M3[row,index] = 1     \n",
    "if k>1:\n",
    "    if subgroup_indices == 0:                                \n",
    "        M4 = np.eye(d*(d-1),d*(d-1))                                # L2, Sk     \n",
    "\n",
    "    elif subgroup_indices == 1 or 2:                                # Zk, D2k\n",
    "        M4 = np.zeros((d*(d-1),d*(d-1)))\n",
    "        M4[0:k-1,0:k-1] = np.eye(k-1)\n",
    "        key_loc_Zk = ((d-k)*d) + k - 1\n",
    "        M4[k-1, key_loc_Zk] = 1\n",
    "        if subgroup_indices == 1:\n",
    "            M4[k:(2*k)-1, -d+1:-d+k] = np.eye(k-1)\n",
    "            key_loc_D2k = ((k-2)*d)\n",
    "            M4[(2*k)-1, key_loc_D2k] = 1\n",
    "else:\n",
    "    M4 =  np.zeros((d*(d-1),d*(d-1)))\n",
    "    M4[0,0] = 1               \n",
    "\n",
    "return M3, M4\n",
    "    \n",
    "filepath = 'saved_model.h5'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                            save_best_only=True,\n",
    "                                            save_weights_only=True,)\n",
    "\n",
    "Model_discover = CyclicGroupInvarianceDiscover(d)\n",
    "M1, M2 = get_matrix(d)\n",
    "adam = Adam(learning_rate=1e-3)\n",
    "sample_output = Model_discover(val_ds)\n",
    "\n",
    "Model_discover.layers[0].trainable = False                    # Linear1\n",
    "Model_discover.layers[1].trainable = False\n",
    "Model_discover.layers[2].trainable = False\n",
    "Model_discover.layers[3].trainable = False                    # Linear 2\n",
    "\n",
    "Model_discover.compile(optimizer=adam, loss='mae')\n",
    "# initial_weights=Model_discover.get_weights()\n",
    "# Model_discover.set_weights(initial_weights)\n",
    "\n",
    "bias_l1 = np.zeros(d*(d-1))\n",
    "bias_l2 = np.zeros(d*(d-1))\n",
    "\n",
    "Model_discover.layers[1].set_weights([M1.T, bias_l1])\n",
    "Model_discover.layers[2].set_weights([M2.T, bias_l2])\n",
    "\n",
    "initial_weights=Model_discover.get_weights()\n",
    "Model_discover.set_weights(initial_weights)\n",
    "print(Model_discover.summary())     \n",
    "\n",
    "def generate_matrix(k_,subgroup_indices):\n",
    "#k_=int(np.random.choice(divisors,1,replace=False))\n",
    "train_indices=np.sort(np.random.choice(list(range(0,d)),k_,replace=False))\n",
    "#Generate matrix\n",
    "L1, L2 = new_matrix(len(train_indices),d,train_indices,subgroup_indices)\n",
    "#print('Matrix:',matrix)\n",
    "return L1, L2, train_indices\n",
    "\n",
    "def generate_matrix_given_indices(train_indices,subgroup_indices):\n",
    "#Generate matrix\n",
    "L1, L2 = new_matrix(len(train_indices),d,train_indices,subgroup_indices)\n",
    "#print('Matrix:',matrix)\n",
    "return L1, L2\n",
    "\n",
    "def get_loss(M5,M6):\n",
    "Model_discover.set_weights(initial_weights)\n",
    "#sample_output=Model_discover(val_ds)\n",
    "bias1 = np.zeros(d)\n",
    "bias2 = np.zeros(d*(d-1))\n",
    "Model_discover.layers[0].set_weights([M5.T, bias1])\n",
    "Model_discover.layers[3].set_weights([M6.T, bias2])\n",
    "\n",
    "start=time.time()\n",
    "train_history=Model_discover.fit(train_ds,train_y, \n",
    "                    epochs=250,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(val_ds,val_y),\n",
    "                    callbacks=[callback]) \n",
    "end=time.time()\n",
    "print('Time:',end-start)\n",
    "\n",
    "return train_history\n",
    "\n",
    "C = [list(combinations(range(d), i)) for i in range(1, d+1)]\n",
    "C = [list(item) for sublist in C for item in sublist]\n",
    "\n",
    "At = np.zeros((len(C), d))\n",
    "for i, idx in zip(range(len(C)), C):\n",
    "At[i][idx] = 1\n",
    "\n",
    "# Normalization\n",
    "# l2_norms_rows = LA.norm(At, 2, axis=1)[:, np.newaxis]\n",
    "# At = At/l2_norms_rows\n",
    "At = np.hstack((At, np.ones((At.shape[0], 1))))\n",
    "\n",
    "s_arms = np.hstack((At, np.array([[1, 0, 0]] * At.shape[0])))\n",
    "d_arms = np.hstack((At, np.array([[0, 1, 0]] * At.shape[0])))\n",
    "z_arms = np.hstack((At, np.array([[0, 0, 1]] * At.shape[0])))\n",
    "\n",
    "At = np.vstack((s_arms, d_arms, z_arms))\n",
    "print('At shape:',At.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat_array = np.load('./c_5_10_val_data_r_ts_10_mu_hat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03813555]\n",
      " [-0.03497517]\n",
      " [ 0.04030601]\n",
      " [ 0.0406984 ]\n",
      " [-0.02181704]\n",
      " [-0.02062657]\n",
      " [ 0.04395113]\n",
      " [ 0.02622271]\n",
      " [-0.0356758 ]\n",
      " [-0.04604933]\n",
      " [-0.33285396]\n",
      " [-0.10504241]\n",
      " [-0.10886836]\n",
      " [-0.11894319]]\n"
     ]
    }
   ],
   "source": [
    "mu_hat = mu_hat_array[-1]\n",
    "print(mu_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = At"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "costs = contexts.dot(mu_hat)\n",
    "\n",
    "#Pick best arm\n",
    "choosen_arm = np.argmax(costs)\n",
    "contexts_t = contexts[choosen_arm]\n",
    "print(contexts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.where(contexts_t[:-4] > 0)[0].tolist()\n",
    "print(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-205",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
